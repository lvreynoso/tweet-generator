#!/usr/bin/env python3
# tokenize.py
# module for creating lists of tokens from a text

def generate(source_text):
    tokens = source_text.split()
    return tokens